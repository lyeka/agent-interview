# 名词解释生成指南

> 费曼学习法：用最简单的语言解释复杂概念

## 生成位置

在 `00-index.md` 末尾增加「核心术语速查」章节，集中解释所有术语。

## 费曼学习法讲解原则

**核心思想**：如果你不能用简单的语言解释一个概念，说明你还没真正理解它。

**目标读者**：对 AI/LLM 有基础了解，但不熟悉该项目特定术语的工程师。

## 讲解模板

每个术语按以下结构解释：

```markdown
### {术语} ({英文全称})

> **一句话**：{用最简单的语言说清楚是什么}
>
> **类比**：{用日常生活中的例子类比}
>
> **为什么重要**：{解释这个概念解决了什么问题}
>
> **在本项目中**：{说明在当前项目里怎么用的}
```

## 示例

### KG (Knowledge Graph) - 知识图谱

> **一句话**：用"点"和"线"把知识连起来的图。
>
> **类比**：想象一张人物关系图——每个人是一个点，"朋友"、"同事"、"亲属"是连接他们的线。知识图谱就是把所有知识都这样连起来。
>
> **为什么重要**：传统搜索只能找到包含关键词的文档，但知识图谱能回答"马斯克的公司的竞争对手是谁"这种需要"跳两步"的问题。
>
> **在本项目中**：LightRAG 从文档中自动提取实体（人名、公司名）和关系（收购、投资），构建知识图谱，让 AI 能回答复杂问题。

### RAG (Retrieval-Augmented Generation) - 检索增强生成

> **一句话**：先查资料，再回答问题。
>
> **类比**：就像开卷考试——你不需要背下所有知识，只需要知道去哪里查，然后用查到的资料回答问题。
>
> **为什么重要**：LLM 的知识有截止日期，而且可能"编造"答案。RAG 让 LLM 基于真实文档回答，减少幻觉。
>
> **在本项目中**：LightRAG 是一个 RAG 框架，它先从知识图谱和向量数据库中检索相关信息，再让 LLM 生成答案。

### Embedding - 向量嵌入

> **一句话**：把文字变成一串数字，让计算机能"理解"语义。
>
> **类比**：就像给每个词分配一个 GPS 坐标——意思相近的词，坐标也相近。"国王"和"女王"的坐标很近，"国王"和"苹果"的坐标很远。
>
> **为什么重要**：计算机不懂文字，但懂数字。Embedding 让计算机能计算"两段话有多相似"。
>
> **在本项目中**：{根据项目实际填写}

### Agent - 智能代理

> **一句话**：能自己思考、决策、行动的 AI 程序。
>
> **类比**：就像一个实习生——你给他一个任务，他会自己想办法完成：查资料、问问题、写代码、测试，遇到问题还会调整策略。
>
> **为什么重要**：传统程序只能执行预设的步骤，Agent 能根据情况动态决策，处理开放式问题。
>
> **在本项目中**：{根据项目实际填写}

### ReAct (Reasoning + Acting) - 推理行动循环

> **一句话**：先想清楚要做什么，再去做，做完再想下一步。
>
> **类比**：就像解数学题——先读题（观察），想解法（推理），动笔算（行动），检查答案（观察），发现错了就换个方法（推理）...
>
> **为什么重要**：让 AI 能像人一样"边想边做"，而不是一次性输出所有答案。
>
> **在本项目中**：{根据项目实际填写}

### MCP (Model Context Protocol) - 模型上下文协议

> **一句话**：让 AI 能调用外部工具的标准接口。
>
> **类比**：就像 USB 接口——不管是键盘、鼠标还是U盘，只要符合 USB 标准就能插上电脑用。MCP 让各种工具都能被 AI 调用。
>
> **为什么重要**：AI 本身只能生成文字，MCP 让它能读文件、查数据库、调 API，变成真正有用的助手。
>
> **在本项目中**：{根据项目实际填写}

### Token - 词元

> **一句话**：LLM 处理文字的最小单位，大约是 3/4 个英文单词或 1/2 个中文字。
>
> **类比**：就像乐高积木——LLM 不是一个字一个字读的，而是把文字拆成"积木块"来处理。
>
> **为什么重要**：LLM 有 Token 上限（如 128K），超过就处理不了。Token 数量也决定了 API 费用。
>
> **在本项目中**：{根据项目实际填写}

### Context Window - 上下文窗口

> **一句话**：LLM 一次能"看到"的最大文字量。
>
> **类比**：就像人的短期记忆——你能同时记住的电话号码是有限的。LLM 的 Context Window 就是它的"记忆容量"。
>
> **为什么重要**：对话太长会超出 Context Window，LLM 就会"忘记"前面说的话。
>
> **在本项目中**：{根据项目实际填写}

### Chunking - 文档切块

> **一句话**：把长文档切成小段，方便检索和处理。
>
> **类比**：就像把一本书拆成章节——你不需要读完整本书才能找到某个知识点，只需要找到相关的章节。
>
> **为什么重要**：LLM 有 Token 限制，不能一次处理整本书。切块后可以只检索相关的部分。
>
> **在本项目中**：{根据项目实际填写}

## 必须解释的核心术语

根据项目类型，选择需要解释的术语：

### Agent 相关
- Agent（智能代理）
- ReAct（推理行动循环）
- Plan-and-Execute（计划执行模式）
- Tool Calling（工具调用）
- MCP（模型上下文协议）
- Multi-Agent（多智能体）

### LLM 相关
- LLM（大语言模型）
- Prompt（提示词）
- Token（词元）
- Context Window（上下文窗口）
- Embedding（向量嵌入）
- Fine-tuning（微调）
- Hallucination（幻觉）

### RAG 相关
- RAG（检索增强生成）
- KG（知识图谱）
- Vector Search（向量搜索）
- Chunking（文档切块）
- Reranker（重排序器）
- Hybrid Search（混合检索）

### 架构相关
- Async/Await（异步编程）
- Adapter Pattern（适配器模式）
- Workspace Isolation（工作空间隔离）
- Dependency Injection（依赖注入）

## 生成原则

1. **只解释项目中实际用到的术语**，不要堆砌无关概念
2. **"在本项目中"必须具体**，引用实际的文件/函数/模块
3. **类比要贴近生活**，避免用另一个技术术语来解释
4. **一句话定义要精准**，能让人 3 秒内理解核心含义
