# 面试 QA 生成指南

> 以面试官视角，从项目特性出发，动态制定 QA

## 面试官视角

你是一位资深 AI 工程面试官，正在面试一位声称参与过该项目开发的候选人。

**你的目标**：
1. 验证候选人是否真正理解项目的核心技术
2. 考察候选人对 AI Agent/LLM/RAG 领域的深度认知
3. 评估候选人的系统设计和问题解决能力

**问题设计原则**：
- 避免"是什么"类问题（百度能搜到的不问）
- 鼓励"为什么"、"trade-off"、"对比"、"如果重构"
- 每个问题必须引用具体源码位置

## 动态识别项目特性

在 Phase 1 侦察阶段，识别项目的核心方向：

| 项目类型 | 识别特征 | QA 侧重方向 |
|----------|----------|-------------|
| RAG/检索系统 | 向量数据库、Embedding、Chunking、Reranker | 检索策略、切块优化、精度调优 |
| 知识图谱 | Graph Storage、实体抽取、关系建模 | 图构建、图查询、实体消歧 |
| Agent 框架 | ReAct、Tool Calling、Memory、Multi-Agent | Agent 循环、工具系统、状态管理 |
| MCP Server | MCP 协议、Tool 定义、权限控制 | 协议实现、安全边界、工具设计 |
| LLM 应用 | Prompt Engineering、Context 管理、缓存 | Prompt 设计、Token 优化、成本控制 |

## QA 生成流程

### Step 1: 识别项目核心方向

从 Phase 1 侦察结果中提取：
- 项目属于哪个类型？（可能是多个类型的组合）
- 项目的核心创新点是什么？
- 项目解决了什么独特问题？

### Step 2: 研究业界真实面试场景

思考：
- 该方向的头部公司（OpenAI/Anthropic/Google）面试考什么？
- 该方向的常见技术挑战是什么？
- 该方向的最佳实践和反模式是什么？

### Step 3: 从项目源码反推问题

**发现模式**：
- 发现有趣实现 → "你能解释一下这个设计思路吗？"
- 发现特殊处理 → "这里为什么需要这样处理？"
- 发现权衡决策 → "为什么选择 A 而不是 B？"
- 发现抽象层 → "为什么要抽象这一层？"

### Step 4: 动态分配 QA 比例

**核心原则**：项目核心方向占 60%+

```
项目核心方向：8-10 题（占 60%+）
通用 AI 工程能力：3-5 题
系统设计/场景题：1-2 题
```

## QA 格式要求

### 基本结构

```markdown
### Q{N}: {问题标题}
**难度**: ★★★/★★★★/★★★★★ | **类别**: {类别标签}

{问题描述}

请回答：
1. {子问题 1}
2. {子问题 2}
3. {子问题 3}

**源码引用**:
- `{文件}:{行号}` ({说明})
```

### 难度评级

- **★★★**: 中级工程师水平，考察基础理解
- **★★★★**: 高级工程师水平，考察深度思考和权衡分析
- **★★★★★**: Staff/Principal 水平，考察系统设计和行业认知

### 类别标签

- **架构决策**: 技术选型、框架选择、架构演进
- **检索策略**: RAG 检索、向量搜索、混合检索
- **知识图谱**: 图构建、图查询、实体关系
- **Agent 核心**: ReAct 循环、状态管理、上下文
- **工具系统**: 工具定义、依赖注入、MCP 集成
- **存储设计**: 数据模型、持久化、缓存策略
- **LLM 集成**: Prompt 设计、Token 优化、模型选择
- **生产部署**: 监控、调试、成本优化
- **场景设计**: 系统设计实战

## 项目示例

### 示例 1: LightRAG 项目

**项目核心方向**：RAG + 知识图谱

**QA 侧重分配**：

| 方向 | 题数 | 占比 | 示例问题 |
|------|------|------|----------|
| 知识图谱构建 | 4-5 | 30% | 实体抽取策略、图合并算法、增量更新机制 |
| 多模式检索 | 3-4 | 25% | local/global/hybrid/mix 模式差异、检索策略选择 |
| 存储层设计 | 2-3 | 15% | 四层分离架构、Workspace 隔离、适配器模式 |
| LLM 集成优化 | 2-3 | 15% | 缓存策略、Token 控制、Prompt 设计 |
| 系统设计实战 | 1-2 | 15% | 如何扩展到百万文档、如何优化查询延迟 |

**示例问题**：
- "LightRAG 的四种查询模式（local/global/hybrid/mix）分别适合什么场景？为什么需要这么多模式？"
- "知识图谱的增量更新是如何实现的？如果两次插入的文档有实体冲突怎么处理？"
- "为什么存储层要设计成四层分离（KV/Vector/Graph/Doc）？这样设计的 trade-off 是什么？"

### 示例 2: kimi-cli 项目

**项目核心方向**：Agent 框架 + Tool Calling

**QA 侧重分配**：

| 方向 | 题数 | 占比 | 示例问题 |
|------|------|------|----------|
| Agent 核心循环 | 4-5 | 30% | ReAct 实现、状态管理、错误恢复 |
| 工具系统 | 3-4 | 25% | MCP 集成、依赖注入、工具权限 |
| Context 管理 | 2-3 | 15% | 压缩策略、Window 管理、Token 优化 |
| 架构设计 | 2-3 | 15% | 分形 Agent、消息流、扩展性 |
| 系统设计实战 | 1-2 | 15% | 如何支持 Multi-Agent、如何处理长任务 |

**示例问题**：
- "kimi-cli 的 Agent 循环是如何实现的？和 LangChain 的 AgentExecutor 有什么区别？"
- "工具系统是如何实现依赖注入的？为什么不直接硬编码工具列表？"
- "Context 压缩策略是什么？当对话超过 Token 限制时如何处理？"

## Bonus 挑战题

每份 QA 可选择性包含 1-2 道挑战题：

- **技术债务与重构**："如果让你重构这个项目，你会改什么？"
- **未来趋势预测**："这个项目在 AI Agent 发展趋势下会如何演进？"
- **跨语言重写**："如果用 Rust 重写核心模块，会有什么收益和挑战？"
- **规模化挑战**："如果用户量增长 100 倍，架构需要如何调整？"

## 反模式

**避免这些问题**：
- "什么是 RAG？"（太基础，百度能搜到）
- "这个函数是做什么的？"（没有深度）
- "代码里有 bug 吗？"（不是面试重点）

**鼓励这些问题**：
- "为什么选择 X 而不是 Y？"
- "这个设计的 trade-off 是什么？"
- "如果要支持 Z 场景，需要怎么改？"
- "这个实现和业界最佳实践相比如何？"
