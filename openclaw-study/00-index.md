# OpenClaw 深度学习索引

> **分析版本**: `631102e71413e13cfb701368711db342d732e8f1` (main)
> **分析日期**: 2026-02-12
> **仓库地址**: git@github.com:openclaw/openclaw.git

**重要提示**：本文档基于上述版本的源码分析生成。如果源码已更新，部分内容（如行号引用、代码片段）可能与最新版本不符。

```bash
# 切换到分析版本
git checkout 631102e71413e13cfb701368711db342d732e8f1
```

## 项目定位

OpenClaw 是一个本地优先的多通道个人 AI 助手网关平台。它在用户设备上运行一个 Gateway 控制平面（WebSocket + HTTP），将 AI Agent 能力统一投射到 WhatsApp、Telegram、Slack、Discord、Signal、iMessage 等消息通道中。

技术栈：TypeScript (ESM) + Node.js 22+ + Pi SDK (Agent Runtime) + SQLite/sqlite-vec (Memory) + Express (HTTP) + ws (WebSocket) + pnpm (Monorepo)

## 章节导航

| 章节 | 主题 | 核心内容 |
|------|------|----------|
| 01 | 整体架构设计 | 三层架构模型、消息路由流程、会话键设计、认证体系 |
| 02 | Gateway 控制平面 | WebSocket 协议、RPC 方法体系、事件广播、状态模型 |
| 03 | Agent 运行时与会话 | Pi SDK 嵌入模式、会话生命周期、工具系统、工作空间 |
| 04 | Memory 系统设计 | 双层记忆架构、混合搜索、增量索引、嵌入提供者 |
| 05 | 插件与扩展架构 | 插件生命周期、SDK API、钩子系统、Skills vs Plugins |
| 06 | 核心源码深度解析 | 7 段关键源码的逐行分析 |
| 07 | 面试 QA | 15 道高质量面试题 |
| 08 | 知识图谱总结 | 关系图、检查清单、学习路径 |

## 学习路径

### 新手路径（3-4 小时）
1. 先读本索引的术语速查，建立概念基础
2. 读 `01-architecture.md` 理解系统全貌
3. 按顺序阅读 02 → 03 → 04 → 05
4. 最后做 `08-summary.md` 的检查清单自测

### 进阶路径（2-3 小时）
1. 直接读 `07-interview-qa.md`
2. 遇到不懂的概念回溯到对应章节
3. 重点关注 `06-deep-dive.md` 的源码分析

### 速成路径（1 小时）
1. 只读本索引 + `08-summary.md`
2. 重点看架构图和检查清单
3. 面试前过一遍 QA

---

## 核心术语速查

### Gateway (网关)

> **一句话**：所有消息和命令的中央调度站。
>
> **类比**：就像机场的控制塔——飞机（消息）从各个方向飞来，控制塔决定它们在哪条跑道降落、哪个登机口停靠。
>
> **为什么重要**：没有 Gateway，各个通道、Agent、UI 之间无法通信。它是整个系统的单一连接点。
>
> **在本项目中**：Gateway 运行在 `ws://127.0.0.1:18789`，使用 WebSocket 三帧协议（req/res/event）和 Express HTTP 服务。

### Control Plane (控制平面)

> **一句话**：管理"如何做事"的层，而不是"做事"本身。
>
> **类比**：就像公司的管理层——他们不亲自写代码，但决定谁写什么、资源怎么分配、进度怎么跟踪。
>
> **为什么重要**：将控制逻辑（路由、状态、配置）与业务逻辑（Agent 推理、通道通信）分离，降低耦合。
>
> **在本项目中**：Gateway 是控制平面，Agent Runtime 是数据平面。Gateway 决定消息路由到哪个 Agent，Agent 负责实际处理。

### Channel Plugin (通道插件)

> **一句话**：连接一个外部消息平台的适配器。
>
> **类比**：就像手机上的 SIM 卡——不同运营商用不同的 SIM 卡，但手机（Gateway）不关心你用哪个运营商。
>
> **为什么重要**：让 OpenClaw 可以同时连接十几个消息平台，而核心代码不需要了解每个平台的 API。
>
> **在本项目中**：Telegram、Discord、Slack 等都是通道插件，通过 `registerChannel()` 注册到 Gateway。

### Session Key (会话键)

> **一句话**：唯一标识一个对话上下文的字符串。
>
> **类比**：就像电话号码——它同时编码了国家（通道）、运营商（账号）和个人（对话方），一个号码唯一定位一个通话。
>
> **为什么重要**：确保不同通道、不同用户的对话完全隔离，互不干扰。
>
> **在本项目中**：格式为 `agent:{agentId}:{channel}:{accountId}:{peerKind}:{peerId}`，从键名即可反推完整路由信息。

### Hybrid Search (混合搜索)

> **一句话**：同时用"理解含义"和"匹配关键词"两种方式搜索。
>
> **类比**：就像在图书馆找书——你既可以让图书管理员推荐（语义搜索），也可以在目录卡片里查关键词（FTS 搜索），然后把两种结果合在一起看。
>
> **为什么重要**：纯语义搜索可能漏掉精确关键词，纯关键词搜索理解不了同义词。混合搜索兼顾两者。
>
> **在本项目中**：Memory 系统用 sqlite-vec 做向量搜索（权重 0.7）+ FTS5 做关键词搜索（权重 0.3），然后加权融合。

### Embedding (向量嵌入)

> **一句话**：把文字变成一串数字，让计算机能"理解"语义。
>
> **类比**：就像给每段话分配一个 GPS 坐标——意思相近的话坐标也相近。"我喜欢 TypeScript"和"我偏好 TS"的坐标会很接近。
>
> **为什么重要**：Memory 搜索的核心能力——将用户查询和存储的记忆都转为向量，计算它们的相似度。
>
> **在本项目中**：支持 OpenAI/Gemini/Voyage/Local 四种嵌入提供者，auto 模式优先使用本地 `embeddinggemma-300M` 模型。

### Plugin Slot (插件槽位)

> **一句话**：限制同一类插件只能激活一个的机制。
>
> **类比**：就像 USB 接口——一个接口只能插一个设备。Memory 槽位只能被 memory-core 或 memory-lancedb 其中一个占据。
>
> **为什么重要**：避免两个 Memory 插件同时注册同名工具（如 memory_search），导致冲突。
>
> **在本项目中**：`plugins.slots.memory` 配置项决定激活哪个 Memory 插件，默认为 `"memory-core"`。

### Pi SDK (Pi Agent 运行时)

> **一句话**：提供 Agent 推理和工具调用能力的核心引擎。
>
> **类比**：就像汽车的发动机——OpenClaw 是整辆车（车身、方向盘、座椅），Pi SDK 是让车跑起来的引擎。
>
> **为什么重要**：Agent 的"思考"能力来自 Pi SDK——它管理与 LLM 的对话、工具调用、上下文压缩。
>
> **在本项目中**：以嵌入模式运行在 Gateway 进程内，通过 `createAgentSession` 创建 Agent 会话。

### ReAct (Reasoning + Acting)

> **一句话**：先想清楚要做什么，再去做，做完再想下一步。
>
> **类比**：就像解数学题——读题（观察），想解法（推理），动笔算（行动），检查结果（观察），发现错了换方法（推理）...
>
> **为什么重要**：让 AI 能像人一样"边想边做"，而不是一次性输出所有答案。
>
> **在本项目中**：Pi Agent 使用 ReAct 循环：接收消息 → LLM 推理 → 决定调用工具或回复 → 观察结果 → 继续推理。

### Hook (钩子)

> **一句话**：在系统执行某个动作前后插入自定义代码的机制。
>
> **类比**：就像快递中转站的检查点——包裹（消息/事件）经过时，检查员可以检查、修改甚至拦截。
>
> **为什么重要**：让插件能参与 Agent 生命周期，而不需要修改核心代码。
>
> **在本项目中**：15 种钩子覆盖 Agent、消息、工具、会话、Gateway 的完整生命周期。分为 void（并行观察）和 modifying（串行修改）两种模式。

### Token (词元)

> **一句话**：LLM 处理文字的最小单位，大约是 3/4 个英文单词或 1/2 个中文字。
>
> **类比**：就像乐高积木——LLM 不是一个字一个字读的，而是把文字拆成"积木块"来处理。
>
> **为什么重要**：LLM 有 Token 上限（如 200K），超过就处理不了。Token 数量也决定了 API 费用。Memory 的分块大小就以 Token 为单位。
>
> **在本项目中**：Memory 分块默认 512 tokens/块，overlap 64 tokens。嵌入批处理上限 8000 tokens。

### Context Window (上下文窗口)

> **一句话**：LLM 一次能"看到"的最大文字量。
>
> **类比**：就像人的短期记忆——你能同时记住的电话号码是有限的。Context Window 就是 LLM 的"记忆容量"。
>
> **为什么重要**：对话太长会超出 Context Window，LLM 就会"忘记"前面说的话。这是 Memory 系统存在的根本原因——让 Agent 能超越 Context Window 的限制。
>
> **在本项目中**：当上下文接近 Token 上限时，会话自动触发 compaction（上下文压缩），生成摘要替代完整历史。

### ACP (Agent Client Protocol)

> **一句话**：让 IDE 和 AI Agent 对话的标准接口。
>
> **类比**：就像 USB-C 接口——不管是充电、传数据还是接显示器，一个接口搞定。ACP 让不同的 IDE 都能接入 OpenClaw。
>
> **为什么重要**：使 OpenClaw 可以作为 Cursor、VSCode 等 IDE 的 AI 后端，扩展了使用场景。
>
> **在本项目中**：`src/acp/` 实现了 ACP 桥接，将 ACP 消息翻译为 Gateway 协议的 `chat.send` 方法。
