# LightRAG 深度学习索引

> **分析版本**: `2626497a77cfa5b35ca3b5e447ebb68a68be52b8` (main)
> **分析日期**: 2026-01-31
> **仓库地址**: https://github.com/HKUDS/LightRAG

**重要提示**：本文档基于上述版本的源码分析生成。如果源码已更新，部分内容（如行号引用、代码片段）可能与最新版本不符。

```bash
# 切换到分析版本
git checkout 2626497a77cfa5b35ca3b5e447ebb68a68be52b8
```

## 项目定位

LightRAG 是香港大学数据科学实验室（HKUDS）开源的**知识图谱增强 RAG 框架**，通过将传统向量检索与知识图谱结合，实现了比纯向量 RAG 更精准的语义检索。它介于 LangChain（通用编排）与 GraphRAG（微软重型方案）之间，以"轻量级"为核心设计理念，在保持功能完整的同时大幅降低 LLM 调用成本。

**核心创新**：
- 四层存储分离架构（KV/Vector/Graph/DocStatus）
- 五种检索模式（local/global/hybrid/mix/naive）
- 15+ 存储后端支持（从 JSON 到 Neo4j 无缝切换）
- 生产就绪（FastAPI 服务、JWT 认证、Gunicorn 部署）

## 章节导航

| 章节 | 主题 | 核心内容 |
|------|------|----------|
| 01 | 整体架构 | LightRAG 类设计、初始化流程、数据流 |
| 02 | 知识图谱构建 | 实体提取、关系建模、图合并算法 |
| 03 | 多模式检索 | local/global/hybrid/mix/naive 五种模式 |
| 04 | LLM 集成 | 提供商抽象、Prompt 工程、缓存策略 |
| 05 | 存储架构 | 四层分离、多租户隔离、适配器模式 |
| 06 | API 与部署 | FastAPI 服务、JWT 认证、Gunicorn 配置 |
| 07 | 评估体系 | RAGAS 集成、可观测性、Langfuse |
| 08 | 面试 QA | 15 道核心面试题 |
| 09 | 集成实战 | 快速上手、进阶配置、最佳实践 |
| 10 | 知识总结 | 架构图、检查清单、学习路径 |

## 学习路径

### 新手路径（推荐）

```
00-index → 01-architecture → 02-kg → 03-query → 08-qa
```

先建立整体认知，再深入核心模块，最后通过 QA 检验理解。

### 进阶路径

```
08-qa → 遇到不懂的概念 → 回溯对应章节 → 05-storage → 04-llm
```

直接从面试题入手，带着问题学习，重点关注存储和 LLM 集成。

### 速成路径

```
00-index → 10-summary → 08-qa
```

只看索引、总结和 QA，适合时间紧迫的面试准备。

---

## 核心术语速查

### RAG（Retrieval-Augmented Generation）

**一句话定义**：让 LLM 在回答问题前先"查资料"的技术。

**生活类比**：就像开卷考试——你可以翻书找答案，但最终还是要用自己的话组织回答。

**为什么重要**：LLM 的知识有截止日期，RAG 让它能访问最新信息；LLM 会"幻觉"，RAG 提供事实依据。

**在本项目中**：LightRAG 是 RAG 框架，但不是普通的向量 RAG，而是知识图谱增强的 RAG。

### 知识图谱（Knowledge Graph）

**一句话定义**：用"实体-关系-实体"三元组表示知识的图结构。

**生活类比**：就像人物关系图——"张三（实体）是（关系）李四（实体）的朋友"。

**为什么重要**：向量检索只能找"相似"的内容，知识图谱能找"相关"的内容（通过关系推理）。

**在本项目中**：LightRAG 从文档中自动提取实体和关系，构建知识图谱，然后用图谱增强检索。

### Embedding

**一句话定义**：把文本转换成数字向量的技术。

**生活类比**：就像给每个词/句子分配一个"GPS 坐标"，语义相近的文本坐标也相近。

**为什么重要**：计算机不懂文字，但懂数字。Embedding 是文本和计算机之间的翻译器。

**在本项目中**：LightRAG 用 Embedding 把实体、关系、文本块都转成向量，存入向量数据库。

### Chunking（文本分块）

**一句话定义**：把长文档切成小块的技术。

**生活类比**：就像把一本书拆成一页一页——太长的内容 LLM 处理不了，需要分块喂给它。

**为什么重要**：LLM 有 Token 限制（如 128K），长文档必须分块；分块策略影响检索质量。

**在本项目中**：LightRAG 用 Token-aware 滑动窗口分块，默认 1200 Token/块，100 Token 重叠。

### Reranker

**一句话定义**：对初步检索结果进行二次排序的模型。

**生活类比**：就像搜索引擎的"相关性排序"——先粗筛，再精排。

**为什么重要**：向量检索是"近似"匹配，Reranker 能更精准地判断相关性。

**在本项目中**：LightRAG 支持 BAAI/bge-reranker-v2-m3 和 Jina rerankers，默认启用。

### Workspace（工作空间）

**一句话定义**：数据隔离的命名空间。

**生活类比**：就像不同的"项目文件夹"——每个 workspace 的数据互不干扰。

**为什么重要**：多租户场景下，不同用户/项目的数据需要隔离。

**在本项目中**：LightRAG 通过 workspace 参数实现数据隔离，不同存储后端有不同的隔离策略（子目录/前缀/字段）。

### Token

**一句话定义**：LLM 处理文本的最小单位。

**生活类比**：就像"字符"，但不完全是——一个英文单词可能是 1-3 个 Token，一个中文字通常是 1-2 个 Token。

**为什么重要**：LLM 按 Token 计费，Token 数量决定成本；LLM 有 Token 上限，超过会截断。

**在本项目中**：LightRAG 有精确的 Token 预算控制系统（max_entity_tokens + max_relation_tokens + max_total_tokens）。

### local/global/hybrid/mix 模式

**一句话定义**：LightRAG 的四种知识图谱检索策略。

**生活类比**：
- **local**：问"张三是谁"——聚焦特定实体
- **global**：问"公司的组织架构"——宏观主题
- **hybrid**：问"张三在公司的角色"——结合两者
- **mix**：hybrid + 向量检索——最全面

**为什么重要**：不同问题适合不同检索策略，选错策略会影响回答质量。

**在本项目中**：推荐使用 mix 模式（配合 Reranker），它结合了知识图谱和向量检索的优势。

### N-ary 关系分解

**一句话定义**：把多元关系拆成二元关系的技术。

**生活类比**："张三、李四、王五一起吃饭"→"张三和李四吃饭"+"李四和王五吃饭"+"张三和王五吃饭"。

**为什么重要**：图数据库天然支持二元关系，多元关系需要分解才能存储。

**在本项目中**：LightRAG 的实体提取 Prompt 强制要求 N-ary 关系分解为 binary pairs。

---

## 章节衔接

**本章回顾**：
- 我们了解了 LightRAG 的项目定位和核心创新
- 关键收获：知识图谱增强 RAG、四层存储分离、五种检索模式

**下一章预告**：
- 在 `01-architecture.md` 中，我们将学习 LightRAG 的整体架构
- 为什么需要学习：理解架构是深入源码的基础
- 关键问题：LightRAG 类是如何组织的？初始化流程是什么？数据如何流动？
